{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HLab.hmd.text import get_window\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import dgl\n",
    "from HLab.hmd import Utilities as Util\n",
    "from HLab.hmd.preprocessing import *\n",
    "from HLab.hmd.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = fetch_20newsgroups(\n",
    "        data_home=Util.get_data_path('20newsgroups'),\n",
    "        subset='test',\n",
    "        return_X_y=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
      "Subject: Need info on 88-89 Bonneville\n",
      "Organization: University at Buffalo\n",
      "Lines: 10\n",
      "News-Software: VAX/VMS VNEWS 1.41\n",
      "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_src = []\n",
    "edges_dst = []\n",
    "edge_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StringPreprocessing()\n",
    "preprocessor.add_handler(ToLowerCase())\n",
    "preprocessor.add_handler(RemoveWhiteSpace())\n",
    "preprocessor.add_handler(RemovePunctuation())\n",
    "preprocessor.add_handler(EnglishTokenizer())\n",
    "\n",
    "corpus = [preprocessor.execute(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532\n",
      "98479\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern=r\"\\S+\")\n",
    "tfidf_vec = vectorizer.fit_transform(corpus)\n",
    "lexicon = vectorizer.vocabulary_\n",
    "\n",
    "doc_nodes = len(corpus)\n",
    "word_nodes = len(lexicon)\n",
    "num_nodes = doc_nodes + word_nodes\n",
    "\n",
    "print(doc_nodes)\n",
    "print(word_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate tfidf edge: 7532it [00:01, 7005.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(enumerate(tfidf_vec), desc=\"generate tfidf edge\"):\n",
    "    for col_ind, value in zip(row.indices, row.data):\n",
    "        edges_src.append(idx) # doc_id\n",
    "        edges_dst.append(doc_nodes + col_ind) # word_id\n",
    "        edge_features.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split by window: 100%|██████████| 7532/7532 [01:01<00:00, 122.93it/s]\n",
      "Calculate pmi between words: 100%|██████████| 10220817/10220817 [00:08<00:00, 1196824.40it/s]\n"
     ]
    }
   ],
   "source": [
    "word_window_freq, word_pair_count, windows_count = get_window(corpus, 20)\n",
    "pmi_edge_lst = count_pmi(word_window_freq, word_pair_count, windows_count, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_item in pmi_edge_lst:    \n",
    "    w1_idx = doc_nodes + lexicon[edge_item[0]]\n",
    "    w2_idx = doc_nodes + lexicon[edge_item[1]]\n",
    "    edges_src.append(w1_idx) # word_1\n",
    "    edges_dst.append(w2_idx) # word_2\n",
    "    edge_features.append(edge_item[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [lbl + 1 for lbl in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532\n",
      "7532\n",
      "98479\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "\n",
    "print(doc_nodes)\n",
    "print(word_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106011\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "word_labels = [0] * word_nodes\n",
    "labels = labels + word_labels\n",
    "print(len(labels))\n",
    "print(labels[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_src = torch.from_numpy(np.array(edges_src))\n",
    "edges_dst = torch.from_numpy(np.array(edges_dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = doc_nodes + word_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.graph(\n",
    "    (edges_src, edges_dst), num_nodes=num_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.add_reverse_edges(graph) # chuyển về đồ thị vô hướng\n",
    "graph = dgl.add_self_loop(graph) # + eye matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.ndata[\"labels\"] = torch.from_numpy(np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "def normalize(adj):\n",
    "    \"\"\" normalize adjacency matrix with normalization-trick that is faithful to\n",
    "    the original paper.\n",
    "\n",
    "    Arguments:\n",
    "        a (scipy.sparse.coo_matrix): Unnormalied adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.coo_matrix: Normalized adjacency matrix\n",
    "    \"\"\"\n",
    "    # no need to add identity matrix because self connection has already been added\n",
    "    # a += sp.eye(a.shape[0])\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    # ~D in the GCN paper\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_pygcn(adj):\n",
    "    \"\"\" normalize adjacency matrix with normalization-trick. This variant\n",
    "    is proposed in https://github.com/tkipf/pygcn .\n",
    "    Refer https://github.com/tkipf/pygcn/issues/11 for the author's comment.\n",
    "\n",
    "    Arguments:\n",
    "        a (scipy.sparse.coo_matrix): Unnormalied adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.coo_matrix: Normalized adjacency matrix\n",
    "    \"\"\"\n",
    "    # no need to add identity matrix because self connection has already been added\n",
    "    # a += sp.eye(a.shape[0])\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    rowsum_inv = np.power(rowsum, -1).flatten()\n",
    "    rowsum_inv[np.isinf(rowsum_inv)] = 0.\n",
    "    # ~D in the GCN paper\n",
    "    d_tilde = sp.diags(rowsum_inv)\n",
    "    return d_tilde.dot(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# shape = (num_nodes, num_nodes)\n",
    "# indices = torch.from_numpy(np.vstack((edges_src, edges_dst)).astype(np.int64))\n",
    "# values = torch.FloatTensor(edge_features)\n",
    "# shape = torch.Size(shape)\n",
    "\n",
    "# features = torch.sparse_coo_tensor(indices, values, shape)\n",
    "# print(type(features))\n",
    "# # graph.ndata[\"features\"] = normalize(features)\n",
    "\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# eye \n",
    "for i in range(len(num_nodes)):\n",
    "    edges_src.append(i)\n",
    "    edges_dst.append(i)\n",
    "    edge_features.append(1)\n",
    "\n",
    "adj = coo_matrix((edge_features, (edges_src, edges_dst)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "\n",
    "adj_norm = normalize(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from v064mb9kubvmsdccbuffaloedu neil b gandler subject need info on 8889 bonneville organization university at buffalo lines 10 newssoftware vaxvms vnews 141 nntppostinghost ubvmsdccbuffaloedu i am a little confused on all of the models of the 8889 bonnevilles i have heard of the le se lse sse ssei could someone tell me the differences are far as features or performance i am also curious to know what the book value is for prefereably the 89 model and how much less than book value can you usually get them for in other words how much are they in demand this time of year i have heard that the midspring early summer is the best time to buy neil gandler\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(corpus[i])\n",
    "print(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1082)\n",
      "  (0, 22275)\t0.07703137119748274\n",
      "  (0, 19618)\t0.06618728473856625\n",
      "  (0, 85778)\t0.10818219952536623\n",
      "  (0, 34111)\t0.08827121802476652\n",
      "  (0, 59883)\t0.177224866723644\n",
      "  (0, 87975)\t0.026082547669486207\n",
      "  (0, 97657)\t0.06894060223817204\n",
      "  (0, 88690)\t0.09831481888634297\n",
      "  (0, 88280)\t0.029295757202467628\n",
      "  (0, 30743)\t0.11361619870204591\n",
      "  (0, 88190)\t0.037868017944496825\n",
      "  (0, 95971)\t0.0826568359989083\n",
      "  (0, 67904)\t0.045579393315896714\n",
      "  (0, 46908)\t0.04498579100579172\n",
      "  (0, 88037)\t0.04650826076532019\n",
      "  (0, 40900)\t0.04419955617778666\n",
      "  (0, 92332)\t0.08395122624587281\n",
      "  (0, 97856)\t0.03039177515100854\n",
      "  (0, 23273)\t0.0357510300495787\n",
      "  (0, 87952)\t0.04646600901917184\n",
      "  (0, 53349)\t0.07191621527809072\n",
      "  (0, 62913)\t0.10529879385363713\n",
      "  (0, 45385)\t0.0892523736246828\n",
      "  (0, 15540)\t0.022718123388412535\n",
      "  (0, 61342)\t0.08972224993144326\n",
      "  :\t:\n",
      "  (0, 15187)\t0.10126610859075477\n",
      "  (0, 45972)\t0.09481744138039236\n",
      "  (0, 90813)\t0.142835899691619\n",
      "  (0, 65423)\t0.03517416052146206\n",
      "  (0, 2380)\t0.09979629961555507\n",
      "  (0, 93799)\t0.09725469468010779\n",
      "  (0, 92997)\t0.09541190004078601\n",
      "  (0, 65006)\t0.09541190004078601\n",
      "  (0, 899)\t0.06557793679962653\n",
      "  (0, 53826)\t0.019241317971200027\n",
      "  (0, 21908)\t0.10353484232785377\n",
      "  (0, 17351)\t0.035191744442011015\n",
      "  (0, 91567)\t0.036946689636208445\n",
      "  (0, 67658)\t0.019938370629862902\n",
      "  (0, 20850)\t0.163921398289409\n",
      "  (0, 11806)\t0.327842796578818\n",
      "  (0, 67152)\t0.05782292084565494\n",
      "  (0, 47375)\t0.07636860408840151\n",
      "  (0, 64593)\t0.05648951633287249\n",
      "  (0, 85451)\t0.01919284793669366\n",
      "  (0, 40303)\t0.3012358597103481\n",
      "  (0, 18095)\t0.07745090370320558\n",
      "  (0, 64664)\t0.25454367872901773\n",
      "  (0, 92554)\t0.177224866723644\n",
      "  (0, 39638)\t0.01919284793669366\n"
     ]
    }
   ],
   "source": [
    "dat_i = features[i]\n",
    "# for idx, val in enumerate(dat_i):\n",
    "#     if val.numpy() != 0:\n",
    "#         print(idx)\n",
    "\n",
    "print(dat_i[85778+doc_nodes])\n",
    "    \n",
    "print(tfidf_vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_indices = [i for i in range(num_nodes)]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(node_indices, labels, test_size=0.33, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask[x_train] = True\n",
    "val_mask[val_mask] = True\n",
    "test_mask[test_mask] = True\n",
    "\n",
    "\n",
    "graph.ndata[\"train_mask\"] = train_mask\n",
    "graph.ndata[\"val_mask\"] = val_mask\n",
    "graph.ndata[\"test_mask\"] = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata[\"features\"]\n",
    "    labels = g.ndata[\"labels\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    val_mask = g.ndata[\"val_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\n",
    "                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(labels)) + 1\n",
    "model = GCN(graph.ndata[\"features\"].shape[1], 200, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(graph, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
